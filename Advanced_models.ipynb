{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4f0df2190874cd7a62a5f525586b146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6d3d9cca3ab43c1a89b28d3ac713c6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90d6521f60e34001a224f292ac4078b6",
              "IPY_MODEL_26af82642ba549ada691d783b7f3dddd"
            ]
          }
        },
        "c6d3d9cca3ab43c1a89b28d3ac713c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90d6521f60e34001a224f292ac4078b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_215701ee48bc439c887af6dbd3c4a706",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f072190dc64f47168eff3385fb20a333"
          }
        },
        "26af82642ba549ada691d783b7f3dddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc197c7d50e4437694fa64e1cd8031c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760k/760k [00:01&lt;00:00, 697kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a45ec27fa00242a58d9bcd91c3fbc82c"
          }
        },
        "215701ee48bc439c887af6dbd3c4a706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f072190dc64f47168eff3385fb20a333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc197c7d50e4437694fa64e1cd8031c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a45ec27fa00242a58d9bcd91c3fbc82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cdeca2d97a64873aaaec1e2c0be1fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b38d6b37443b4eea9e361e0af841957e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b4caa29f7ae4c4583db97bce0c60a3a",
              "IPY_MODEL_7c5fdc64f24347bfa7822e2899d82717"
            ]
          }
        },
        "b38d6b37443b4eea9e361e0af841957e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b4caa29f7ae4c4583db97bce0c60a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39697d704f8d4e90bba04c3f229ce41b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1312669,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1312669,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e8cb581085a479295ebec6894f2d88f"
          }
        },
        "7c5fdc64f24347bfa7822e2899d82717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb6be3e0339c4f5c85f855a053896df4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 1.82MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc7fe8d6bc6d4094803ed2b3ef65a55d"
          }
        },
        "39697d704f8d4e90bba04c3f229ce41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e8cb581085a479295ebec6894f2d88f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb6be3e0339c4f5c85f855a053896df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc7fe8d6bc6d4094803ed2b3ef65a55d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1a80501a33549888c1482643c9aa73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ddcf0f1107494f30ae9d6d47e13ea533",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_062ff324979545e6b8833d4d156826a6",
              "IPY_MODEL_fa0c20525ce540648e3ea1f7ef204f80"
            ]
          }
        },
        "ddcf0f1107494f30ae9d6d47e13ea533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "062ff324979545e6b8833d4d156826a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f76fd7de38a1439ba16ca61ddeaadbca",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87599,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87599,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a051c563581488cb1830ce59ce48610"
          }
        },
        "fa0c20525ce540648e3ea1f7ef204f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0688d7be73d4bf9a96cff1e147d0712",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87599/87599 [01:48&lt;00:00, 806.99ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0ed805aaa554624aafcba6839f31d2d"
          }
        },
        "f76fd7de38a1439ba16ca61ddeaadbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a051c563581488cb1830ce59ce48610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0688d7be73d4bf9a96cff1e147d0712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0ed805aaa554624aafcba6839f31d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "531d0c28f3934f7e88ca382a32fa127c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6e655ca30944d048fe0004f37f5f8a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8d8b918763a409faddf993fbb530db8",
              "IPY_MODEL_57ee6f11f0c44802a9d3fe0e81beaf61"
            ]
          }
        },
        "d6e655ca30944d048fe0004f37f5f8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8d8b918763a409faddf993fbb530db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27adb0694cc94a96b0f394836648d2e7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a0fa2e2088c4ead82693d5d75512b76"
          }
        },
        "57ee6f11f0c44802a9d3fe0e81beaf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3cb12e127064bf0a915e7baf984593c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10570/10570 [00:19&lt;00:00, 528.61ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff00cc469c79475aa5fa22b65842ce7a"
          }
        },
        "27adb0694cc94a96b0f394836648d2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a0fa2e2088c4ead82693d5d75512b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3cb12e127064bf0a915e7baf984593c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff00cc469c79475aa5fa22b65842ce7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunsinghrathore/ARSAVEWILDLIFE/blob/master/Advanced_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAxOwKJ3N41R"
      },
      "source": [
        "# ALBERT(from HuggingFace Transformers) for Text Extraction\n",
        "\n",
        "The abstract from the paper is the following:\n",
        "\n",
        "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations, longer training times, and unexpected model degradation. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large.\n",
        "\n",
        "It basically presents two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT:\n",
        "1. Splitting the embedding matrix into two smaller matrices.\n",
        "2. Using repeating layers split among groups.\n",
        "\n",
        "However the computational cost remains similar to a BERT-like architecture with the same number of hidden layers as it has to iterate through the same number of (repeating) layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiomlPG-N41U"
      },
      "source": [
        "## Introduction to Dataset & Training Method\n",
        "\n",
        "The model was first fine-tuned with Stanford Question-Answering Dataset(SQuAD).\n",
        "In SQuAD, an input consists of a question, and a paragraph for context.\n",
        "The goal is to find the span of text in the paragraph that answers the question.\n",
        "We evaluate our performance on this data with the \"Exact Match\" metric,\n",
        "which measures the percentage of predictions that exactly match any one of the\n",
        "ground-truth answers.\n",
        "\n",
        "We fine-tune a ALBERT model to perform this task as follows:\n",
        "\n",
        "1. Feed the context and the question as inputs to ALBERT.\n",
        "2. Take two vectors S and T with dimensions equal to that of\n",
        "   hidden states in ALBERT.\n",
        "3. Compute the probability of each token being the start and end of\n",
        "   the answer span. The probability of a token being the start of\n",
        "   the answer is given by a dot product between S and the representation\n",
        "   of the token in the last layer of ALBERT, followed by a softmax over all tokens.\n",
        "   The probability of a token being the end of the answer is computed\n",
        "   similarly with the vector T.\n",
        "4. Fine-tune ALBERT and learn S and T along the way.\n",
        "\n",
        "**References:**\n",
        "\n",
        "- [ALBERT](https://arxiv.org/abs/1909.11942)\n",
        "- [SQuAD](https://arxiv.org/abs/1606.05250)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkILnQywN41V"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-otuMksOWGX",
        "outputId": "72203db7-e26e-45a8-ef7d-b23d3ff0c7da"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsxnQAreowEZ",
        "outputId": "1cabd290-d1fc-4a88-beb6-4b3e81fb0f93"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 37.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mceIrgjFQr9U",
        "outputId": "dcb277e2-df3c-4115-c26a-c56971d275b3"
      },
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "!pip install sentence-transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 6.6MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.3\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 27.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 transformers-4.6.1\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/75/df441011cd1726822b70fbff50042adb4860e9327b99b346154ead704c44/sentence-transformers-1.2.0.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.2.0-cp37-none-any.whl size=123339 sha256=5433a1c636c571ee0ad0f24e6bb2e143f048ae74a9175b7ca4eada88c5d02419\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/06/f7/faaa96fdda87462b4fd5c47b343340e9d5531ef70d0eef8242\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-1.2.0 sentencepiece-0.1.95\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n",
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/f8/ff7cd6e3b400b33dcbbfd31c6c1481678a2b2f669f521ad20053009a9aa3/datasets-1.7.0-py3-none-any.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, fsspec, datasets\n",
            "Successfully installed datasets-1.7.0 fsspec-2021.5.0 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD23c4spN41V"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import AlbertTokenizerFast, TFAlbertModel, AlbertConfig\n",
        "import sentencepiece\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from transformers import T5TokenizerFast, T5Config, TFT5Model\n",
        "from datasets import load_dataset\n",
        "import datasets\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G47XZ52FvAsT",
        "outputId": "64aec680-6ccb-4fab-eb40-0869692c8c7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdImGOdgXaqt"
      },
      "source": [
        "# **Fine Tuning on Squad**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF33iKkPpD0P"
      },
      "source": [
        "configuration = AlbertConfig()  # default parameters and configuration for ALBERT"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xau6Sz_LN41X"
      },
      "source": [
        "## Load the Data & Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpU7_ae1eAon"
      },
      "source": [
        "The data is downloaded first by using the  JSON path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLBbBGGlN41X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7188b2f-653a-405f-ec47-14fd240171e3"
      },
      "source": [
        "train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
        "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
        "eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\n",
        "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "30294016/30288272 [==============================] - 0s 0us/step\n",
            "Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "4857856/4854279 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e5NH0y65d6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "f4f0df2190874cd7a62a5f525586b146",
            "c6d3d9cca3ab43c1a89b28d3ac713c6d",
            "90d6521f60e34001a224f292ac4078b6",
            "26af82642ba549ada691d783b7f3dddd",
            "215701ee48bc439c887af6dbd3c4a706",
            "f072190dc64f47168eff3385fb20a333",
            "cc197c7d50e4437694fa64e1cd8031c7",
            "a45ec27fa00242a58d9bcd91c3fbc82c",
            "9cdeca2d97a64873aaaec1e2c0be1fa4",
            "b38d6b37443b4eea9e361e0af841957e",
            "9b4caa29f7ae4c4583db97bce0c60a3a",
            "7c5fdc64f24347bfa7822e2899d82717",
            "39697d704f8d4e90bba04c3f229ce41b",
            "6e8cb581085a479295ebec6894f2d88f",
            "eb6be3e0339c4f5c85f855a053896df4",
            "bc7fe8d6bc6d4094803ed2b3ef65a55d"
          ]
        },
        "outputId": "566d675b-d2f1-4649-cf4d-dc6a2378a759"
      },
      "source": [
        "# The tokenizer is loaded, we used the fast tokenizer from huggingface\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4f0df2190874cd7a62a5f525586b146",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cdeca2d97a64873aaaec1e2c0be1fa4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1312669.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS0UaYSeN41X"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "1. Go through the JSON file and store every record as a SquadExample object.\n",
        "2. Go through each SquadExample and create x_train, y_train, x_eval, y_eval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIz4OklIhKpI"
      },
      "source": [
        "max_len = 384 # The maximum length is set as 384"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fipvmimaN41Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15db5545-d61e-4858-ee2e-4551f3d9d6fd"
      },
      "source": [
        "# SquadExample class is used for making an object for each question in SQuAD\n",
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Clean context, answer and question\n",
        "        context = \" \".join(str(context).split())\n",
        "        question = \" \".join(str(question).split())\n",
        "        answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Mark the character indexes in context that are in answer\n",
        "        is_char_in_ans = [0] * len(context)\n",
        "        for idx in range(start_char_idx, end_char_idx):\n",
        "            is_char_in_ans[idx] = 1\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer(context, return_offsets_mapping=True)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        ans_token_idx = []\n",
        "        for idx, start_end in enumerate(tokenized_context['offset_mapping']):\n",
        "            start = start_end[0]\n",
        "            end = start_end[1]\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\n",
        "                ans_token_idx.append(idx)\n",
        "\n",
        "        if len(ans_token_idx) == 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = ans_token_idx[0]\n",
        "        end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer(question, return_offsets_mapping=True)\n",
        "\n",
        "        # Create inputs\n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        token_type_ids = [0] * len(tokenized_context['input_ids']) + [1] * len(\n",
        "            tokenized_question['input_ids'][1:]\n",
        "        )\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0:  # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:  # skip\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_context['offset_mapping']\n",
        "\n",
        "# Training & Validation Data is Loaded\n",
        "with open(train_path) as f:\n",
        "    raw_train_data = json.load(f)\n",
        "\n",
        "with open(eval_path) as f:\n",
        "    raw_eval_data = json.load(f)\n",
        "\n",
        "\n",
        "def create_squad_examples(raw_data):\n",
        "    squad_examples = []\n",
        "    for item in tqdm(raw_data[\"data\"]):\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                squad_eg = SquadExample(\n",
        "                    question, context, start_char_idx, answer_text, all_answers\n",
        "                )\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_squad_examples = create_squad_examples(raw_train_data)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 6/442 [00:01<02:28,  2.94it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            " 57%|█████▋    | 254/442 [00:52<00:39,  4.77it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRmMu0Ej5N5-"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94YBp-4RN41a"
      },
      "source": [
        "Create the Question-Answering Model using BERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuwlV89pN41a"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## Pretrained ALBERT encoder\n",
        "    encoder = TFAlbertModel.from_pretrained(\"albert-large-v2\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    # Getting the Contextual EMbeddings from ALBERT\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "\n",
        "    # Making a model for using the embeddings trained on SQuAD QA when fine-tuning on UNIV-AI1 QA Data\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    # embedding_model.load_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')\n",
        "\n",
        "    # The probability for identifying the start index of the attention span\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "    # The probability for identifying the end index of the attention span\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "    # Softmax is applied for getting the probabilities\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    return model, embedding_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfFxl12N41b"
      },
      "source": [
        "We advise this notebook to be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 10 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHh8NNtjN41b"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDyRDrYaTnNt"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gty4nKhtN41c"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will compute the exact match score & F1 score using the validation data\n",
        "after every epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4lcpq-IN41c"
      },
      "source": [
        "from collections import Counter\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def f1_score_fn(prediction_tokens, ground_truth_tokens):\n",
        "    # prediction_tokens = normalize_answer(prediction).split()\n",
        "    # ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "# Iterating over each possible answer and finding if any of our predictions match\n",
        "def intermediate_for_f1(metric_fn, prediction, ground_truths):\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "class ExactMatch(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Each `SquadExample` object contains the character level offsets for each token\n",
        "    in its input paragraph. We use them to get back the span of text corresponding\n",
        "    to the tokens between our predicted start and end tokens.\n",
        "    All the ground-truth answers are also present in each `SquadExample` object.\n",
        "    We calculate the percentage of data points where the span of text obtained\n",
        "    from model predictions matches one of the ground-truth answers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        f1_score = 0\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\n",
        "            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\n",
        "            f1_score += intermediate_for_f1(f1_score_fn, normalized_pred_ans, normalized_true_ans)\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        f1_score = f1_score / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}, f1 score={f1_score:.2f}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRExDpBN41d"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar0yG8hoN41d"
      },
      "source": [
        "exact_match_callback = ExactMatch(x_eval, y_eval)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=3,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=64,\n",
        "    callbacks=[exact_match_callback],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNM0SMxCXJjk"
      },
      "source": [
        "embedding_model.save_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rypIijAzhveQ"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/univai/Project/squad_whole_model.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX8YTmhNgLBa"
      },
      "source": [
        "# **Fine Tuning on UNIV AI Dataset With Manually Added Context**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IGtZOW9kPQQ"
      },
      "source": [
        "1. For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "2. The context for each question was mapped manually for this section, an automated method will be dsicussed in the coming sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWYoJD1NpGVB"
      },
      "source": [
        "configuration = AlbertConfig()  # default parameters and configuration for ALBERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZtj5W4BgLBd"
      },
      "source": [
        "## Load the Data & Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFIddtLUXnyx"
      },
      "source": [
        "# Your code here\n",
        "def clean_data(data):\n",
        "    message_list = data\n",
        "    for i in range(len(message_list)):\n",
        "        # Lower Case\n",
        "        message = message_list[i].lower()\n",
        "\n",
        "        message = \" \".join([word for word in message.split() if word.find('yes') == -1])\n",
        "        message = \" \".join([word for word in message.split() if word.find('no') == -1])\n",
        "        \n",
        "        message = \" \".join(message.split())\n",
        "\n",
        "        message_list[i] = message\n",
        "\n",
        "    return message_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEdpKSxAgLBd"
      },
      "source": [
        "# Loading the training data including the manually added context\n",
        "df_con = pd.read_csv('/content/drive/MyDrive/univai/Project/faq_context.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "BUg-6A5APmeZ",
        "outputId": "a1e0fc19-2e27-4152-e490-25dc456d92aa"
      },
      "source": [
        "df_con.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Pre-class</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>Are session pre-class quizzes graded?</td>\n",
              "      <td>No. Pre-class quiz is to just check your under...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>When is the deadline for the submission of ses...</td>\n",
              "      <td>5 PM on the day of the following lecture.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>Will there be any extension allowed for the qu...</td>\n",
              "      <td>Only for exceptional cases.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Amount of work</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>How many hours will I need to dedicate to succ...</td>\n",
              "      <td>About 15 hours per week.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Exercise grading</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>Who will grade my exercise?</td>\n",
              "      <td>The exercises are auto-graded once you click t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             Title  ... Unnamed: 2 Unnamed: 3\n",
              "0           0         Pre-class  ...        NaN        NaN\n",
              "1           1         Deadlines  ...        NaN        NaN\n",
              "2           2         Deadlines  ...        NaN        NaN\n",
              "3           3    Amount of work  ...        NaN        NaN\n",
              "4           4  Exercise grading  ...        NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcc1a8hbUX-a"
      },
      "source": [
        "# Getting the Context, Question & Answer in a list. Then cleaning them\n",
        "questions_list = df_con.Question.tolist()\n",
        "clean_questions = clean_data(questions_list)\n",
        "\n",
        "answer_list = df_con.Answer.tolist()\n",
        "clean_answers = clean_data(answer_list)\n",
        "\n",
        "context_list = df_con.Context.tolist()\n",
        "clean_context = clean_data(context_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsfBJy3MWHPX"
      },
      "source": [
        "# Finding the start index for the answer in the context, if not found ind is set at 0\n",
        "start_indexes = []\n",
        "for context, answer in zip(clean_context, clean_answers):\n",
        "  ind = context.find(answer[:20])\n",
        "  if ind == -1:\n",
        "    ind = context.find(answer[:5])\n",
        "  if ind == -1:\n",
        "    ind = 0\n",
        "  start_indexes.append(ind)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMnvJnkhFC_D"
      },
      "source": [
        "# Loading the test dataset with the manually added context\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/univai/Project/test_manual.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "IkpP0fcnFFuH",
        "outputId": "d834f501-af06-44ce-c737-1e5b08b79b03"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Context</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Will the pre-class session be recorded?</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the deadline for quiz submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the deadline for exercise submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many hours do I need to complete this course?</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who will grade the exercise?</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Questions  ... end_idx\n",
              "0            Will the pre-class session be recorded?  ...       2\n",
              "1          What is the deadline for quiz submission?  ...       2\n",
              "2      What is the deadline for exercise submission?  ...       2\n",
              "3  How many hours do I need to complete this course?  ...       2\n",
              "4                       Who will grade the exercise?  ...       2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UXMSQ-zFJTg"
      },
      "source": [
        "# Getting the Context, Question & Answer in a list. Then cleaning them\n",
        "val_questions = df_test.Questions.tolist()\n",
        "val_questions = clean_data(val_questions)\n",
        "\n",
        "val_answers = ['No Provided Answer']*len(val_questions) # Dummy Answer for ease of uniform preprocessing\n",
        "\n",
        "val_context = df_test.Context.tolist()\n",
        "val_context = clean_data(val_context)\n",
        "\n",
        "# Dummy start_idx for ease of uniform preprocessing\n",
        "val_start_idx = df_test.start_idx.tolist()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8tm2kAbgLBe"
      },
      "source": [
        "# Tokenizer is loaded\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOootpX5gLBf"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "1. Go through the JSON file and store every record as a SquadExample object.\n",
        "2. Go through each SquadExample and create x_train, y_train, x_eval, y_eval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrPhGHI2meXt"
      },
      "source": [
        "max_len = 384 # The maximum length is set as 384"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XshlmQkvgLBf",
        "outputId": "3321f350-9970-4531-dc17-86bcd4f4946b"
      },
      "source": [
        "# SquadExample class is used for making an object for each question in SQuAD\n",
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Clean context, answer and question\n",
        "        context = \" \".join(str(context).split())\n",
        "        question = \" \".join(str(question).split())\n",
        "        answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Mark the character indexes in context that are in answer\n",
        "        is_char_in_ans = [0] * len(context)\n",
        "        for idx in range(start_char_idx, end_char_idx):\n",
        "            is_char_in_ans[idx] = 1\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer(context, return_offsets_mapping=True)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        ans_token_idx = []\n",
        "        for idx, start_end in enumerate(tokenized_context['offset_mapping']):\n",
        "            start = start_end[0]\n",
        "            end = start_end[1]\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\n",
        "                ans_token_idx.append(idx)\n",
        "\n",
        "        if len(ans_token_idx) == 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = ans_token_idx[0]\n",
        "        end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer(question, return_offsets_mapping=True)\n",
        "\n",
        "        # Create inputs\n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        token_type_ids = [0] * len(tokenized_context['input_ids']) + [1] * len(\n",
        "            tokenized_question['input_ids'][1:]\n",
        "        )\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0:  # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:  # skip\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_context['offset_mapping']\n",
        "\n",
        "\n",
        "def create_squad_examples(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "    squad_examples = []\n",
        "   \n",
        "    for ques, cont, ans, idx in zip(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "      question = ques\n",
        "      context = cont\n",
        "      answer_text = ans\n",
        "      start_char_idx = idx\n",
        "      squad_eg = SquadExample(\n",
        "          question, context, start_char_idx, answer_text\n",
        "      )\n",
        "      squad_eg.preprocess()\n",
        "      squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_squad_examples = create_squad_examples(clean_questions, clean_context, clean_answers, start_indexes)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(val_questions, val_context, val_answers, val_start_idx)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33 training points created.\n",
            "24 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ6BR19dgLBf"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2llTZSR4gLBf"
      },
      "source": [
        "Create the Question-Answering Model using BERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yowTw4jHgLBg"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## Pretrained ALBERT encoder\n",
        "    encoder = TFAlbertModel.from_pretrained(\"albert-large-v2\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    # Getting the Contextual EMbeddings from ALBERT\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "\n",
        "    # Initializing the embedding of ALBERT from the fine-tuned weights of SQuAD\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    embedding_model.load_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')\n",
        "\n",
        "    # The probability for identifying the start index of the attention span\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "    # The probability for identifying the end index of the attention span\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "    # Softmax is applied for getting the probabilities\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/squad_whole_model.h5')\n",
        "    return model, embedding_model\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E27V5HytgLBg"
      },
      "source": [
        "We advise this notebook to be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 1 second.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b02GNW7gLBg",
        "outputId": "ad2e18b6-7ab7-4037-8633-0b4da906d546"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff1f26a5e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff1f26a5e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff1f26a5e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff2092a5dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff2092a5dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7ff2092a5dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8ZNRCKgLBg",
        "outputId": "4a74b4e2-a832-4fbc-b43d-e422fbbf3383"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 17,686,016\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65IUECwtgLBh"
      },
      "source": [
        "#For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the \n",
        "#above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "albert_layer = model.get_layer('tf_albert_model')\n",
        "albert_layer.trainable = False"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOZ7nvBRgLBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b960870f-f038-4edb-c0b0-f97c5eca05cc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 2,048\n",
            "Non-trainable params: 17,683,968\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPnS73rMgLBh"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will will save the a CSV file containing the question and it's predicted answer for each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAgHfR9gLBh"
      },
      "source": [
        "from collections import Counter\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuations\n",
        "    exclude = set(string.punctuation)\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    # Remove articles\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    text = re.sub(regex, \" \", text)\n",
        "\n",
        "    # Remove extra white space\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "class Predicted_Ans(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        predicted_answers = []\n",
        "        questions = []\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\n",
        "\n",
        "            questions.append(normalize_text(squad_eg.question))\n",
        "            predicted_answers.append(normalized_pred_ans)\n",
        "\n",
        "        df_dict = {'Question' : questions, 'Answer' : predicted_answers}\n",
        "        df = pd.DataFrame(df_dict, columns=['Question','Answer'])\n",
        "        if epoch%1 == 0:\n",
        "          df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/manual_predicted_albert' + str(epoch) + '.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV_KpAmQgLBh"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9K5u1tLgLBi",
        "outputId": "4e02e0ca-1d56-4f04-ae2a-d1bc8193c0f4"
      },
      "source": [
        "predicted_answers = Predicted_Ans(x_eval, y_eval)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=5,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=33,\n",
        "    callbacks=[predicted_answers],\n",
        ")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 77s 77s/step - loss: 11.9293 - activation_loss: 6.1506 - activation_1_loss: 5.7787 - activation_accuracy: 0.0000e+00 - activation_1_accuracy: 0.0952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 6.4023 - activation_loss: 3.4005 - activation_1_loss: 3.0019 - activation_accuracy: 0.9048 - activation_1_accuracy: 0.8095\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 3.7685 - activation_loss: 1.8797 - activation_1_loss: 1.8888 - activation_accuracy: 0.9524 - activation_1_accuracy: 0.8571\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 2.2025 - activation_loss: 1.0166 - activation_1_loss: 1.1859 - activation_accuracy: 0.9524 - activation_1_accuracy: 0.9048\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 1.5125 - activation_loss: 0.5620 - activation_1_loss: 0.9505 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fef41814c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T_Ot6W2gLBi"
      },
      "source": [
        "# embedding_model.save_weights('/content/drive/MyDrive/univai/Project/Univ_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNmMVAqbgLBi"
      },
      "source": [
        "# model.save_weights('/content/drive/MyDrive/univai/Project/Univ_whole_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foBoYvhFdxQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVFGqmu7dzkr"
      },
      "source": [
        "# **Fine Tuning on UNIV AI Data with Automatically Extracted Context**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGEmq9d_pV21"
      },
      "source": [
        "1. For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "2. The context for each question was found using a Cross-Encoder Trasnformer model which was trained on the MS Marco Dataset for finding the context paragraph for each question. This pretrained model meets our requirement here perfectly, furthermore in the future if enough data of UNIV-AI corpus is retrieved then we can finetuned this cross encoder on it for better results.\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SgyDdjQpHlB"
      },
      "source": [
        "configuration = AlbertConfig()  # default parameters and configuration for ALBERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMGYHgs2eyjs"
      },
      "source": [
        "## **Context Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHZqvQKifb33"
      },
      "source": [
        "# Your code here\n",
        "def clean_data(data):\n",
        "    message_list = data\n",
        "    for i in range(len(message_list)):\n",
        "        # Lower Case\n",
        "        message = message_list[i].lower()\n",
        "\n",
        "        # message = \" \".join([word for word in message.split() if word.find('yes') == -1])\n",
        "        # message = \" \".join([word for word in message.split() if word.find('no') == -1])\n",
        "        \n",
        "        message = \" \".join(message.split())\n",
        "\n",
        "        message_list[i] = message\n",
        "\n",
        "    return message_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9oMY5BefP_j"
      },
      "source": [
        "### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwGhUiVyfb35"
      },
      "source": [
        "df_con = pd.read_csv('/content/drive/MyDrive/univai/Project/faq_context.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "txIvI88CfPFo",
        "outputId": "27fc7649-fd3b-4e18-c0f1-e833f1f796b3"
      },
      "source": [
        "df_con.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Pre-class</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>Are session pre-class quizzes graded?</td>\n",
              "      <td>No. Pre-class quiz is to just check your under...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>When is the deadline for the submission of ses...</td>\n",
              "      <td>5 PM on the day of the following lecture.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>Will there be any extension allowed for the qu...</td>\n",
              "      <td>Only for exceptional cases.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Amount of work</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>How many hours will I need to dedicate to succ...</td>\n",
              "      <td>About 15 hours per week.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Exercise grading</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>Who will grade my exercise?</td>\n",
              "      <td>The exercises are auto-graded once you click t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             Title  ... Unnamed: 2 Unnamed: 3\n",
              "0           0         Pre-class  ...        NaN        NaN\n",
              "1           1         Deadlines  ...        NaN        NaN\n",
              "2           2         Deadlines  ...        NaN        NaN\n",
              "3           3    Amount of work  ...        NaN        NaN\n",
              "4           4  Exercise grading  ...        NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkDf1ISDfIVk"
      },
      "source": [
        "# The possibel contexts\n",
        "contexts = df_con.Context.tolist()\n",
        "contexts = clean_data(contexts)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVrWa-V5fK2M"
      },
      "source": [
        "train_questions = df_con.Question.tolist()\n",
        "train_questions = clean_data(train_questions)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-DzZod4fK4Y"
      },
      "source": [
        "train_answers = df_con.Answer.tolist()\n",
        "train_answers = clean_data(train_answers)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQRcBXn_fK7B"
      },
      "source": [
        "# The pretrained cross encoder model is loaded, with maximum length set at 512\n",
        "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FFE5PJSfLdF"
      },
      "source": [
        "# The score is found for each question against each context vector, the highest score context vector is chosen then for that question.\n",
        "train_contexts = []\n",
        "for question in train_questions:\n",
        "  que_cont = [(question, text) for text in contexts]\n",
        "  scores = model.predict(que_cont)\n",
        "  ind = np.argmax(scores)\n",
        "  train_contexts.append(contexts[ind])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARehHl3xiV6x"
      },
      "source": [
        "# Finding the start index for the answer if available in the context, , if not found ind is set at 0\n",
        "train_start_indexes = []\n",
        "no_ans = 0\n",
        "for context, answer in zip(train_contexts, train_answers):\n",
        "  ind = context.find(answer[:20])\n",
        "  if ind == -1:\n",
        "    ind = context.find(answer[:5])\n",
        "  if ind == -1:\n",
        "    ind = 0\n",
        "    no_ans += 1\n",
        "  train_start_indexes.append(ind)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBc7Hr8-kwjr",
        "outputId": "38158706-b58e-4831-e748-cba63d6c29b3"
      },
      "source": [
        "# Number of questions out of 33 of whom we coudnt find the answer start idx in the automatically found context\n",
        "no_ans"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxuUx_o8ilQT"
      },
      "source": [
        "### **Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHnkz9toitv_"
      },
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/univai/Project/test_manual.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "PlrexE_JitwA",
        "outputId": "8ef40fa1-774d-42e5-8fd0-c79c5f623480"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Context</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Will the pre-class session be recorded?</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the deadline for quiz submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the deadline for exercise submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many hours do I need to complete this course?</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who will grade the exercise?</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Questions  ... end_idx\n",
              "0            Will the pre-class session be recorded?  ...       2\n",
              "1          What is the deadline for quiz submission?  ...       2\n",
              "2      What is the deadline for exercise submission?  ...       2\n",
              "3  How many hours do I need to complete this course?  ...       2\n",
              "4                       Who will grade the exercise?  ...       2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBoJJ_XEitwB"
      },
      "source": [
        "val_questions = df_test.Questions.tolist()\n",
        "val_questions = clean_data(val_questions)\n",
        "\n",
        "# The possible contexts\n",
        "contexts = df_con.Context.tolist()\n",
        "contexts = clean_data(contexts)\n",
        "\n",
        "# Dummy answers and start_idx for ease of pre-processing\n",
        "val_answers = ['No Provided Answer']*len(val_questions)\n",
        "\n",
        "val_start_idx = df_test.start_idx.tolist()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPmu_Cx3ilQY"
      },
      "source": [
        "# The pretrained cross encoder model is loaded, with maximum length set at 512\n",
        "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wclJ1-LbilQZ"
      },
      "source": [
        "# The score is found for each question against each context vector, the highest score context vector is chosen then for that question.\n",
        "val_contexts = []\n",
        "for question in val_questions:\n",
        "  que_cont = [(question, text) for text in contexts]\n",
        "  scores = model.predict(que_cont)\n",
        "  ind = np.argmax(scores)\n",
        "  val_contexts.append(contexts[ind])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zV1C99rdzk0"
      },
      "source": [
        "## Load Tokenizer & Preprocess the data\n",
        "\n",
        "1. Go through the JSON file and store every record as a SquadExample object.\n",
        "2. Go through each SquadExample and create x_train, y_train, x_eval, y_eval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0tUNNGLpG9s"
      },
      "source": [
        "max_len = 384 # The maximum length is set as 384"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM-ErmI8lzs6"
      },
      "source": [
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p972zSSdzk0",
        "outputId": "bd1fb361-7e70-435d-bf76-a04d172fd078"
      },
      "source": [
        "# SquadExample class is used for making an object for each question in SQuAD\n",
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Clean context, answer and question\n",
        "        context = \" \".join(str(context).split())\n",
        "        question = \" \".join(str(question).split())\n",
        "        answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Mark the character indexes in context that are in answer\n",
        "        is_char_in_ans = [0] * len(context)\n",
        "        for idx in range(start_char_idx, end_char_idx):\n",
        "            is_char_in_ans[idx] = 1\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer(context, return_offsets_mapping=True)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        ans_token_idx = []\n",
        "        for idx, start_end in enumerate(tokenized_context['offset_mapping']):\n",
        "            start = start_end[0]\n",
        "            end = start_end[1]\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\n",
        "                ans_token_idx.append(idx)\n",
        "\n",
        "        if len(ans_token_idx) == 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = ans_token_idx[0]\n",
        "        end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer(question, return_offsets_mapping=True)\n",
        "\n",
        "        # Create inputs\n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        token_type_ids = [0] * len(tokenized_context['input_ids']) + [1] * len(\n",
        "            tokenized_question['input_ids'][1:]\n",
        "        )\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0:  # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:  # skip\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_context['offset_mapping']\n",
        "\n",
        "\n",
        "def create_squad_examples(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "    squad_examples = []\n",
        "   \n",
        "    for ques, cont, ans, idx in zip(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "      question = ques\n",
        "      context = cont\n",
        "      answer_text = ans\n",
        "      start_char_idx = idx\n",
        "      squad_eg = SquadExample(\n",
        "          question, context, start_char_idx, answer_text\n",
        "      )\n",
        "      squad_eg.preprocess()\n",
        "      squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_squad_examples = create_squad_examples(train_questions, train_contexts, train_answers, train_start_indexes)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(val_questions, val_contexts, val_answers, val_start_idx)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33 training points created.\n",
            "24 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR5Xw4Icdzk2"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7JC1A5Zdzk2"
      },
      "source": [
        "Create the Question-Answering Model using BERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UbpAe83dzk3"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## Pretrained ALBERT encoder\n",
        "    encoder = TFAlbertModel.from_pretrained(\"albert-large-v2\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    # Getting the Contextual EMbeddings from ALBERT\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "    # Initializing the embedding of ALBERT from the fine-tuned weights of SQuAD\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    embedding_model.load_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')\n",
        "\n",
        "    # The probability for identifying the start index of the attention span\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "    # The probability for identifying the end index of the attention span\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "    # Softmax is applied for getting the probabilities\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/squad_whole_model.h5')\n",
        "    return model, embedding_model\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljyu4XaAdzk3"
      },
      "source": [
        "We advise this notebook to be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 1 second.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDQxkj82dzk3",
        "outputId": "d2fb1a4d-396b-43de-a9c7-23d2dde69269"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f282e248e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f282e248e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f282e248e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f2834e22dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f2834e22dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f2834e22dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL6MAgdvdzk4",
        "outputId": "39a2b538-fc17-4b45-a162-7f90aacd1e27"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 17,686,016\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpgIxmw-dzk4"
      },
      "source": [
        "# For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the \n",
        "#above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "albert_layer = model.get_layer('tf_albert_model')\n",
        "albert_layer.trainable = False"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCTVqFGfdzk5",
        "outputId": "64024c2f-bdb4-4019-de07-3ea238bcb94d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 2,048\n",
            "Non-trainable params: 17,683,968\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8tx3G32dzk5"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will will save the a CSV file containing the question and it's predicted answer for each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvElbJrsdzk5"
      },
      "source": [
        "from collections import Counter\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuations\n",
        "    exclude = set(string.punctuation)\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    # Remove articles\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    text = re.sub(regex, \" \", text)\n",
        "\n",
        "    # Remove extra white space\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "class Predicted_Ans(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        predicted_answers = []\n",
        "        questions = []\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\n",
        "\n",
        "            questions.append(normalize_text(squad_eg.question))\n",
        "            predicted_answers.append(normalized_pred_ans)\n",
        "\n",
        "        df_dict = {'Question' : questions, 'Answer' : predicted_answers}\n",
        "        df = pd.DataFrame(df_dict, columns=['Question','Answer'])\n",
        "        if epoch%1 == 0:\n",
        "          df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/auto_predicted_albert' + str(epoch) + '.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce19SGeodzk6"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Hv59NDdzk6",
        "outputId": "ded7df91-730a-4f11-dc56-ae0ec9a03019"
      },
      "source": [
        "predicted_answers = Predicted_Ans(x_eval, y_eval)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=33,\n",
        "    callbacks=[predicted_answers],\n",
        ")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 76s 76s/step - loss: 12.0311 - activation_loss: 5.6953 - activation_1_loss: 6.3358 - activation_accuracy: 0.1429 - activation_1_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 8.2067 - activation_loss: 3.5914 - activation_1_loss: 4.6153 - activation_accuracy: 0.6786 - activation_1_accuracy: 0.2857\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 6.4834 - activation_loss: 2.6026 - activation_1_loss: 3.8808 - activation_accuracy: 0.9286 - activation_1_accuracy: 0.4286\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 4.9896 - activation_loss: 1.5556 - activation_1_loss: 3.4341 - activation_accuracy: 0.9643 - activation_1_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 3.8897 - activation_loss: 0.8349 - activation_1_loss: 3.0548 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.5357\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 3.2078 - activation_loss: 0.5565 - activation_1_loss: 2.6513 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.6786\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 2.4873 - activation_loss: 0.4427 - activation_1_loss: 2.0446 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.8214\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 1.8030 - activation_loss: 0.2496 - activation_1_loss: 1.5534 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9286\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 1.2696 - activation_loss: 0.0996 - activation_1_loss: 1.1699 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9643\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.8956 - activation_loss: 0.0507 - activation_1_loss: 0.8449 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f25561b5f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5H20vPvmWta"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3-iYaRymXZV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEQJyTQvmXbi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5hnA2XMmXdo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krt055gOmXga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFXrtlnxmXiJ"
      },
      "source": [
        "# masked_texts = []\n",
        "# for text in texts:\n",
        "#   splitt = text.split()\n",
        "#   num_mask = int(0.2*len(splitt))\n",
        "#   rand_ind = np.random.randint(len(splitt), size = num_mask)\n",
        "#   for ind in rand_ind:\n",
        "#     splitt[ind] = '[MASK]'\n",
        "#   masked_texts.append(\" \".join(splitt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-6hXzmtol51"
      },
      "source": [
        "# T5 (from HuggingFace Transformers) for Text Extraction\n",
        "\n",
        "The abstract from the paper is the following:\n",
        "\n",
        "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.\n",
        "\n",
        "So basically T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and the best pretraining methods were used after various trials. In T5 each task is converted into a text-to-text format. T5 works well on a variety of tasks out-of-the-box by prepending a different prefix to the input corresponding to each task, e.g., for translation: translate English to German: …, for summarization: summarize: …."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g4juGfgol54"
      },
      "source": [
        "## Introduction to Datset & Training Method\n",
        "\n",
        "This demonstration uses SQuAD (Stanford Question-Answering Dataset).\n",
        "In SQuAD, an input consists of a question, and a paragraph for context.\n",
        "The goal is to find the span of text in the paragraph that answers the question.\n",
        "We evaluate our performance on this data with the \"Exact Match\" metric,\n",
        "which measures the percentage of predictions that exactly match any one of the\n",
        "ground-truth answers.\n",
        "\n",
        "We fine-tune a T5 model to perform this task as follows:\n",
        "\n",
        "1. Feed the context and the question as inputs to T5 encoder and the answer  the right shifted answer to the decoder input.\n",
        "2. The embeddings from the decoder are taken and sent through a dense softmax layer, with units equal to the vocab of T5 tokenizer.\n",
        "\n",
        "\n",
        "**References:**\n",
        "\n",
        "- [T5](https://arxiv.org/abs/1910.10683)\n",
        "- [SQuAD](https://arxiv.org/abs/1606.05250)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg35yxL_ol55"
      },
      "source": [
        "# **Fine Tuning on Squad**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDJADckbol57"
      },
      "source": [
        "max_len = 384\n",
        "configuration = T5Config()  # default parameters and configuration for BERT"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6StZQG-ol58"
      },
      "source": [
        "## Load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZyRe6mVol58",
        "outputId": "7631c687-dd95-4cc3-cf2a-cec84111a8a5"
      },
      "source": [
        "# load train and validation split of squad\n",
        "train_dataset = load_dataset('squad', split='train')\n",
        "valid_dataset = load_dataset('squad', split='validation')\n",
        "\n",
        "# train_dataset.features"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n",
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAGBZVvRol58"
      },
      "source": [
        "tokenizer = T5TokenizerFast.from_pretrained('t5-base')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqv17U4LaewH"
      },
      "source": [
        "encoder_max_len = 250\n",
        "decoder_max_len = 25 \n",
        "global_counter = 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EiP32k5ol5-"
      },
      "source": [
        "def encode(example, encoder_max_len= 250, decoder_max_len = 25, bool_obj = True):\n",
        "    if global_counter == 1:\n",
        "      bool_obj = False\n",
        "    # print(bool_obj)\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "    answer = example['answers']['text']\n",
        "  \n",
        "    question_plus = f\"answer_me: {str(question)}\"\n",
        "    context_plus = f\"context: {str(context)}\"\n",
        "    \n",
        "    answer_plus = ', '.join([i for i in list(answer)])\n",
        "    answer_plus = f\"<pad> {answer_plus}\"\n",
        "    \n",
        "    encoder_inputs = tokenizer(question_plus, context_plus, truncation=bool_obj, max_length=encoder_max_len, pad_to_max_length=bool_obj)\n",
        "    \n",
        "    decoder_inputs = tokenizer(answer_plus, truncation=bool_obj, max_length=decoder_max_len, pad_to_max_length=bool_obj)\n",
        "    \n",
        "    input_ids = encoder_inputs['input_ids']\n",
        "    input_attention = encoder_inputs['attention_mask']\n",
        "    target_ids = decoder_inputs['input_ids']\n",
        "    target_attention = decoder_inputs['attention_mask']\n",
        "    \n",
        "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
        "               'decoder_input_ids':target_ids, 'decoder_attention_mask':target_attention}\n",
        "    return outputs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "f1a80501a33549888c1482643c9aa73f",
            "ddcf0f1107494f30ae9d6d47e13ea533",
            "062ff324979545e6b8833d4d156826a6",
            "fa0c20525ce540648e3ea1f7ef204f80",
            "f76fd7de38a1439ba16ca61ddeaadbca",
            "1a051c563581488cb1830ce59ce48610",
            "f0688d7be73d4bf9a96cff1e147d0712",
            "c0ed805aaa554624aafcba6839f31d2d",
            "531d0c28f3934f7e88ca382a32fa127c",
            "d6e655ca30944d048fe0004f37f5f8a8",
            "d8d8b918763a409faddf993fbb530db8",
            "57ee6f11f0c44802a9d3fe0e81beaf61",
            "27adb0694cc94a96b0f394836648d2e7",
            "2a0fa2e2088c4ead82693d5d75512b76",
            "a3cb12e127064bf0a915e7baf984593c",
            "ff00cc469c79475aa5fa22b65842ce7a"
          ]
        },
        "id": "ZaULvoprqvm7",
        "outputId": "8ca63d4c-2f45-4e09-f512-886cf96815b8"
      },
      "source": [
        "# map add_eos_to_examples function to the dataset example wise \n",
        "train_ds=  train_dataset.map(encode)\n",
        "global_counter = 1\n",
        "valid_ds=  valid_dataset.map(encode)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1a80501a33549888c1482643c9aa73f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87599.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "531d0c28f3934f7e88ca382a32fa127c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkh_jERIs0Ic"
      },
      "source": [
        "x_train = [np.array(train_ds['input_ids']), np.array(train_ds['attention_mask']), np.array(train_ds['decoder_input_ids'])[:, :-1], np.array(train_ds['decoder_attention_mask'])[:, :-1]]\n",
        "y_train = np.array(train_ds['decoder_input_ids'])[:, 1:]\n",
        "\n",
        "x_eval = [valid_ds['input_ids'], valid_ds['attention_mask']]\n",
        "y_eval = valid_ds['decoder_input_ids']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V28-GrGIY90i"
      },
      "source": [
        "# x_train[2][x_train[2] == 0] = -100"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZkz1Z8eZuqm"
      },
      "source": [
        "# y_train[y_train == 0] = -100"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvV0EZADZL3_",
        "outputId": "9b19430b-900e-4628-e7f7-556dcd896ae2"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87599, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMpqi2WaSoC2",
        "outputId": "6593883e-3d97-4eb9-823a-6c15912bbc48"
      },
      "source": [
        "x_train[3][17]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHIIJjS7STp6",
        "outputId": "22c0e8a4-7e4a-452f-ba05-6d959fe23a83"
      },
      "source": [
        "len(y_eval)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10570"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZHuNG1y3yV5"
      },
      "source": [
        "# configuration.learni"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY88jSdQol5_"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ngwzUbxol5_"
      },
      "source": [
        "Create the Question-Answering Model using BERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FNMphw-ol5_"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## BERT encoder\n",
        "    encoder = TFT5Model.from_pretrained(\"t5-base\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    embedding = encoder(input_ids  = input_ids, decoder_input_ids =decoder_input_ids, attention_mask=attention_mask, decoder_attention_mask = decoder_attention_mask)[0]\n",
        "\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    # embedding_model.load_weights('/content/drive/MyDrive/univai/Project/T5_emb_model.h5')\n",
        "\n",
        "    qa_head = layers.Dense(configuration.vocab_size, name=\"qa_head\", activation = 'softmax')(embedding)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=qa_head)\n",
        "    \n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/T5_model.h5')\n",
        "    return model, embedding_model\n",
        "\n",
        "# def create_model():\n",
        "#   return TFMT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af4grLqkol6A"
      },
      "source": [
        "This code should preferably be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 5-6 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li0D0AVKol6A",
        "outputId": "652f736e-6589-40f6-aa59-6b96ed615c3d"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.109.240.202:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.109.240.202:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "All model checkpoint layers were used when initializing TFT5Model.\n",
            "\n",
            "All the layers of TFT5Model were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff142e8af30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff142e8af30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff142e8af30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff159a84dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff159a84dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7ff159a84dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_t5model (TFT5Model)          TFSeq2SeqModelOutput 222903552   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "qa_head (Dense)                 (None, None, 32128)  24706432    tf_t5model[0][1]                 \n",
            "==================================================================================================\n",
            "Total params: 247,609,984\n",
            "Trainable params: 247,609,984\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNa6wnl4oIXV"
      },
      "source": [
        "# for layer in encoder.layers:\n",
        "#   for weight in layer.weights:\n",
        "#     print(weight.name)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmp-k050qHXI",
        "outputId": "6ce7f2ba-b1ea-4645-c246-1ee585dcfa0e"
      },
      "source": [
        "configuration.tie_word_embeddings"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNVgHGZKol6A"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will compute the exact match score using the validation data\n",
        "after every epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-nfrQI0cicF"
      },
      "source": [
        "MAX_LENGTH = 16"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ86EN0nw7u5"
      },
      "source": [
        "########################################\n",
        "# search strategy: temperature (re-shape)\n",
        "########################################\n",
        "def temperature(logits, temperature):\n",
        "        probs = np.exp(logits / temperature) / np.sum(np.exp(logits / temperature))\n",
        "        return probs\n",
        "\n",
        "\n",
        "########################################\n",
        "# search strategy: nucleus (truncate)\n",
        "########################################\n",
        "def nucleus(probs, p):\n",
        "    \n",
        "    probs /= sum(probs)\n",
        "    sorted_probs = np.sort(probs)[::-1]\n",
        "    sorted_index = np.argsort(probs)[::-1]\n",
        "    cusum_sorted_probs = np.cumsum(sorted_probs)\n",
        "    after_threshold = cusum_sorted_probs > p\n",
        "    if sum(after_threshold) > 0:\n",
        "        last_index = np.where(after_threshold)[0][-1]\n",
        "        candi_index = sorted_index[:last_index]\n",
        "    else:\n",
        "        candi_index = sorted_index[:3] # just assign a value\n",
        "    candi_probs = [probs[i] for i in candi_index]\n",
        "    candi_probs /= sum(candi_probs)\n",
        "    word = np.random.choice(candi_index, size=1, p=candi_probs)[0]\n",
        "  \n",
        "    return word"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mcFIp-Z63N"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  input_ids = np.array(sentence[0]).reshape(1,-1)\n",
        "  attention_mask = np.array(sentence[1]).reshape(1,-1)\n",
        "  decoder_data = tokenizer(\"<pad>\")\n",
        "  decoder_data = {'input_ids' : decoder_data['input_ids'][:-1], 'attention_mask' : decoder_data['attention_mask'][:-1]}\n",
        "  decoder_input_ids = np.array(decoder_data['input_ids']).reshape(1,-1)\n",
        "  decoder_attention_mask = np.array(decoder_data['attention_mask']).reshape(1,-1)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model.predict([input_ids, attention_mask, decoder_input_ids, decoder_attention_mask])\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]#.reshape(-1)\n",
        "    predicted_id = np.argmax(predictions, axis=-1)\n",
        "    # probs = temperature(logits=predictions, temperature=1.0)\n",
        "    # predicted_id = nucleus(probs=probs, p=0.90)\n",
        "    predicted_id = predicted_id[0][0]\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == 1:\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder as its input.\n",
        "    decoder_input_ids = np.append(decoder_input_ids.reshape(-1), np.array([predicted_id])).reshape(1,-1)\n",
        "    decoder_attention_mask = np.ones((1, decoder_input_ids.shape[1]))\n",
        "    # print(decoder_input_ids)\n",
        "\n",
        "  return decoder_input_ids\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer.decode([i for i in prediction[0] if i < tokenizer.vocab_size])\n",
        "  return predicted_sentence"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3taaDAzvPO8"
      },
      "source": [
        "# evaluate()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLvtJ1aVcSGt"
      },
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        # print(ground_truth)\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "def test_metrics(sentences, ground_truths):\n",
        "  f1 = exact_match = total = 0\n",
        "\n",
        "  for i, ground_truth in tqdm(enumerate(ground_truths)):\n",
        "    sentence = [sentences[0][i], sentences[1][i]]\n",
        "    total += 1\n",
        "    prediction = predict(sentence)\n",
        "    gt = tokenizer.decode([i for i in ground_truth if i != 1])\n",
        "    gt = gt.split(',')\n",
        "    temp = gt[0].split()\n",
        "    gt[0] = temp[0]\n",
        "    gt.insert(1, ' ' + \" \".join(temp[1:]))\n",
        "    gt = [gt[0] + gt[i] for i in range(1,len(gt))]\n",
        "    exact_match += metric_max_over_ground_truths(\n",
        "                    exact_match_score, prediction, gt)\n",
        "    f1 += metric_max_over_ground_truths(\n",
        "          f1_score, prediction, gt)\n",
        "    print('\\nReal : ',gt)\n",
        "    print('Pred : ', prediction)\n",
        "\n",
        "  exact_match = 100.0 * exact_match / total\n",
        "  f1 = 100.0 * f1 / total\n",
        "\n",
        "  return {'exact_match': exact_match, 'f1': f1}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGPQSnuuEQvE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec3376f0-fb84-4131-8cb7-37b5da0b9e2b"
      },
      "source": [
        "tokenizer.decode([i for i in y_eval[0] if i != 1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<pad> Denver Broncos, Denver Broncos, Denver Broncos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzoSoVy3ol6E"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgSdgsIPol6E",
        "outputId": "f644040f-da43-41fb-f865-2da5247c45e4"
      },
      "source": [
        "# exact_match_callback = ExactMatch(x_eval, y_eval)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=3,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=16,\n",
        "    validation_split = 0.1\n",
        "    # validation_data = (x_eval, y_eval),\n",
        "    # callbacks=[exact_match_callback],\n",
        ")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 25) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 25) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4928/4928 [==============================] - ETA: 0s - loss: 1.8287 - accuracy: 0.8318"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 25) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4928/4928 [==============================] - 802s 135ms/step - loss: 1.8287 - accuracy: 0.8318 - val_loss: 1.2531 - val_accuracy: 0.8589\n",
            "Epoch 2/3\n",
            "4928/4928 [==============================] - 641s 130ms/step - loss: 1.0588 - accuracy: 0.8817 - val_loss: 0.7637 - val_accuracy: 0.9192\n",
            "Epoch 3/3\n",
            "4928/4928 [==============================] - 641s 130ms/step - loss: 0.6081 - accuracy: 0.9439 - val_loss: 0.4095 - val_accuracy: 0.9642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee57300c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjov3IcJkjnp"
      },
      "source": [
        "# embedding_model.save_weights('/content/drive/MyDrive/univai/Project/T5_emb_model2.h5')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfPF3ivr0wgE"
      },
      "source": [
        "# model.save_weights('/content/drive/MyDrive/univai/Project/T5_model2.h5')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "MFJAPsQ8u0Te",
        "outputId": "3debaaec-9a96-4ce3-9a12-27d959bfaa8c"
      },
      "source": [
        "y_eval.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-41555c4f3423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_eval' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GAvX1ZhjKOd"
      },
      "source": [
        "metrics = test_metrics(x_eval, y_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wD7DHVquwto"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2_gn2nB95vq"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4mVG6Qol6W"
      },
      "source": [
        "preds = model.predict(x_eval[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a84l9tPbol6X"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pby22R6ol6X"
      },
      "source": [
        "# x_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZCP5cA7ol6X"
      },
      "source": [
        "start = np.argmax(preds[0], axis = -1)\n",
        "end = np.argmax(preds[1], axis = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeYVEoV6ol6X"
      },
      "source": [
        "ind = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUOxdSz-ol6X"
      },
      "source": [
        "start[ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3TqW0L1ol6X"
      },
      "source": [
        "end[ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwE8-JsEol6X"
      },
      "source": [
        "y_eval[0][ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIP5VG7lol6X"
      },
      "source": [
        "y_eval[1][ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyby-uAwol6Y"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV9MGmQhol6Y"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FEm0wyzol6Y"
      },
      "source": [
        "xxxx = tokenizer([\"hello my name is arjun\", 'jingalala hoo haa'], [\"What is your name\", 'jhghj fhg hh'], truncation=True, padding=True, return_tensors = 'np', max_length=max_len, return_offsets_mapping=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtgJkYy8ol6Y"
      },
      "source": [
        "xxxx['offset_mapping'][0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1JauWnyol6Y"
      },
      "source": [
        "tokenizer.decode(xxxx['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUy4KeEBol6Y"
      },
      "source": [
        "val_contexts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oj6DGsJol6Y"
      },
      "source": [
        "val_encodings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBL_P7m0q2n6"
      },
      "source": [
        "# **Fine Tuning on Univ AI(With Manual Context)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMlwEVjJq2n8"
      },
      "source": [
        "configuration = T5Config()  # default parameters and configuration for BERT"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYW5ZxOJSgqg",
        "outputId": "09aa6d7c-13b2-4590-efd4-a0ca27e9eb33"
      },
      "source": [
        "tokenizer.pad_token_id"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbu_AkEauHp-"
      },
      "source": [
        "## Load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOG30hVpuHqA"
      },
      "source": [
        "# Your code here\n",
        "def clean_data(data):\n",
        "    message_list = data\n",
        "    for i in range(len(message_list)):\n",
        "        # Lower Case\n",
        "        message = message_list[i].lower()\n",
        "        \n",
        "        message = \" \".join(message.split())\n",
        "\n",
        "        message_list[i] = message\n",
        "\n",
        "    return message_list"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQMTq4_CuHqA"
      },
      "source": [
        "df_con = pd.read_csv('/content/drive/MyDrive/univai/Project/faq_context.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "ekvYnqXzuHqA",
        "outputId": "bdea2518-0a3b-4019-d538-6fc6a8d948ca"
      },
      "source": [
        "df_con.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Pre-class</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>Are session pre-class quizzes graded?</td>\n",
              "      <td>No. Pre-class quiz is to just check your under...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>When is the deadline for the submission of ses...</td>\n",
              "      <td>5 PM on the day of the following lecture.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>Will there be any extension allowed for the qu...</td>\n",
              "      <td>Only for exceptional cases.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Amount of work</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>How many hours will I need to dedicate to succ...</td>\n",
              "      <td>About 15 hours per week.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Exercise grading</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>Who will grade my exercise?</td>\n",
              "      <td>The exercises are auto-graded once you click t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             Title  ... Unnamed: 2 Unnamed: 3\n",
              "0           0         Pre-class  ...        NaN        NaN\n",
              "1           1         Deadlines  ...        NaN        NaN\n",
              "2           2         Deadlines  ...        NaN        NaN\n",
              "3           3    Amount of work  ...        NaN        NaN\n",
              "4           4  Exercise grading  ...        NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06lpXz7FuHqB"
      },
      "source": [
        "questions_list = df_con.Question.tolist()\n",
        "train_questions = clean_data(questions_list)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1Y_b7MuHqB"
      },
      "source": [
        "answer_list = df_con.Answer.tolist()\n",
        "train_answers = clean_data(answer_list)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR3Zmfi7uHqC"
      },
      "source": [
        "context_list = df_con.Context.tolist()\n",
        "train_contexts = clean_data(context_list)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrDDjjlFuHqC"
      },
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/univai/Project/test_manual.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "IyasvgXguHqC",
        "outputId": "896a597e-8a91-4c0c-9489-8e95ca5aa16f"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Context</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Will the pre-class session be recorded?</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the deadline for quiz submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the deadline for exercise submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many hours do I need to complete this course?</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who will grade the exercise?</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Questions  ... end_idx\n",
              "0            Will the pre-class session be recorded?  ...       2\n",
              "1          What is the deadline for quiz submission?  ...       2\n",
              "2      What is the deadline for exercise submission?  ...       2\n",
              "3  How many hours do I need to complete this course?  ...       2\n",
              "4                       Who will grade the exercise?  ...       2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRqWbh1NuHqD"
      },
      "source": [
        "val_questions = df_test.Questions.tolist()\n",
        "val_questions = clean_data(val_questions)\n",
        "\n",
        "val_answers = ['No Provided Answer']*len(val_questions)\n",
        "\n",
        "val_contexts = df_test.Context.tolist()\n",
        "val_contexts = clean_data(val_contexts)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOwab_iq2n-"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "1. Go through the JSON file and store every record as a `SquadExample` object.\n",
        "2. Go through each `SquadExample` and create `x_train, y_train, x_eval, y_eval`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XWz6JHAq2n9"
      },
      "source": [
        "tokenizer = T5TokenizerFast.from_pretrained('t5-base')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B1RB76iq2n_"
      },
      "source": [
        "def preprocess(context, question, answer):\n",
        "    question_plus = f\"answer_me: {str(question)}\"\n",
        "    context_plus = f\"context: {str(context)}\"\n",
        "    \n",
        "    answer_plus = f\"<pad>{str(answer)}\"\n",
        "\n",
        "    return [question_plus, context_plus, answer_plus]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6JsDaMzxos-",
        "outputId": "d06fc7b3-f6cf-4a01-a8f1-625a4ba6f05b"
      },
      "source": [
        "ind = 0\n",
        "for context, question, answer in tqdm(zip(train_contexts, train_questions, train_answers)):\n",
        "  listt = preprocess(context, question, answer)\n",
        "  train_questions[ind] = listt[0]\n",
        "  train_contexts[ind] = listt[1]\n",
        "  train_answers[ind] = listt[2]\n",
        "  ind += 1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33it [00:00, 87992.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkU7xEno7Y_f"
      },
      "source": [
        "enocder_train_inputs = tokenizer(train_questions, train_contexts, pad_to_max_length=True, padding = True)\n",
        "decoder_train_inputs = tokenizer(train_answers, pad_to_max_length=True, padding = True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwmdRjvc0Lfr",
        "outputId": "12076121-5d6b-4df6-9a10-7e62a9e1ea5a"
      },
      "source": [
        "ind = 0\n",
        "for context, question, answer in tqdm(zip(val_contexts, val_questions, val_answers)):\n",
        "  listt = preprocess(context, question, answer)\n",
        "  val_questions[ind] = listt[0]\n",
        "  val_contexts[ind] = listt[1]\n",
        "  val_answers[ind] = listt[2]\n",
        "  ind += 1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24it [00:00, 87609.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPqwtz-_8HdG"
      },
      "source": [
        "enocder_val_inputs = tokenizer(val_questions, val_contexts)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye22DSODq2n_"
      },
      "source": [
        "x_train = [np.array(enocder_train_inputs['input_ids']), np.array(enocder_train_inputs['attention_mask']), np.array(decoder_train_inputs['input_ids'])[:, :-1], np.array(decoder_train_inputs['input_ids'])[:, :-1]]\n",
        "y_train = np.array(decoder_train_inputs['input_ids'])[:, 1:]\n",
        "\n",
        "x_eval = [enocder_val_inputs['input_ids'], enocder_val_inputs['attention_mask']]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFa0EA97TW4z",
        "outputId": "7cbb51f3-6412-413a-984a-1e91817799ec"
      },
      "source": [
        "x_train[2][0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,   150,     5,   554,    18,  4057, 20967,    19,    12,\n",
              "         131,   691,    39,  1705,    13,     8,  1183,     5,    34,\n",
              "          56,    59,  3476,  1587,    39,  2769,     5,     1,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EkVy4idTklf",
        "outputId": "85890434-2b8d-4c66-9996-b31c2705fc44"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  150,     5,   554,    18,  4057, 20967,    19,    12,   131,\n",
              "         691,    39,  1705,    13,     8,  1183,     5,    34,    56,\n",
              "          59,  3476,  1587,    39,  2769,     5,     1,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VqOHYqAq2n_"
      },
      "source": [
        "# x_train[2][x_train[2] == 0] = -100"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2YQFW1Gq2n_"
      },
      "source": [
        "# y_train[y_train == 0] = -100"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdZj5Ih9q2oB"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6h3sBSHq2oB"
      },
      "source": [
        "Create the Question-Answering Model using BERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De942N9rq2oB"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## BERT encoder\n",
        "    encoder = TFT5Model.from_pretrained(\"t5-base\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    embedding = encoder(input_ids  = input_ids, decoder_input_ids =decoder_input_ids, attention_mask=attention_mask, decoder_attention_mask = decoder_attention_mask)[0]\n",
        "\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    embedding_model.load_weights('/content/drive/MyDrive/univai/Project/T5_emb_model.h5')\n",
        "\n",
        "    qa_head = layers.Dense(configuration.vocab_size, name=\"qa_head\", activation = 'softmax')(embedding)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=qa_head)\n",
        "    \n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/T5_univ_man_model.h5')\n",
        "    return model, embedding_model\n",
        "\n",
        "# def create_model():\n",
        "#   return TFMT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kNkH2IEq2oB"
      },
      "source": [
        "This code should preferably be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 5-6 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXg1-dG3q2oB",
        "outputId": "587b0764-901d-437e-c09d-e2559bfcf51f"
      },
      "source": [
        "use_tpu = False\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFT5Model.\n",
            "\n",
            "All the layers of TFT5Model were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6F1SjBY02xI",
        "outputId": "7addec40-8626-4465-bec8-4d2de53bed90"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_t5model_1 (TFT5Model)        TFSeq2SeqModelOutput 222903552   input_5[0][0]                    \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "qa_head (Dense)                 (None, None, 32128)  24706432    tf_t5model_1[0][1]               \n",
            "==================================================================================================\n",
            "Total params: 247,609,984\n",
            "Trainable params: 247,609,984\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_8E_vtxq2oB"
      },
      "source": [
        "t5_layer = model.get_layer('tf_t5model_1')\n",
        "t5_layer.trainable = False"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0NM6dS506zt",
        "outputId": "7758c7b6-0640-4a01-9aeb-b47f09fd6979"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_t5model_1 (TFT5Model)        TFSeq2SeqModelOutput 222903552   input_5[0][0]                    \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "qa_head (Dense)                 (None, None, 32128)  24706432    tf_t5model_1[0][1]               \n",
            "==================================================================================================\n",
            "Total params: 247,609,984\n",
            "Trainable params: 24,706,432\n",
            "Non-trainable params: 222,903,552\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UulRd7Iwq2oC"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will compute the exact match score using the validation data\n",
        "after every epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwe-lsQsq2oC"
      },
      "source": [
        "MAX_LENGTH = 50"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEkLJdDVq2oC"
      },
      "source": [
        "\n",
        "########################################\n",
        "# search strategy: temperature (re-shape)\n",
        "########################################\n",
        "def temperature(logits, temperature):\n",
        "        probs = np.exp(logits / temperature) / np.sum(np.exp(logits / temperature))\n",
        "        return probs\n",
        "\n",
        "\n",
        "########################################\n",
        "# search strategy: nucleus (truncate)\n",
        "########################################\n",
        "def nucleus(probs, p):\n",
        "    \n",
        "    probs /= sum(probs)\n",
        "    sorted_probs = np.sort(probs)[::-1]\n",
        "    sorted_index = np.argsort(probs)[::-1]\n",
        "    cusum_sorted_probs = np.cumsum(sorted_probs)\n",
        "    after_threshold = cusum_sorted_probs > p\n",
        "    if sum(after_threshold) > 0:\n",
        "        last_index = np.where(after_threshold)[0][-1]\n",
        "        candi_index = sorted_index[:last_index]\n",
        "    else:\n",
        "        candi_index = sorted_index[:3] # just assign a value\n",
        "    candi_probs = [probs[i] for i in candi_index]\n",
        "    candi_probs /= sum(candi_probs)\n",
        "    word = np.random.choice(candi_index, size=1, p=candi_probs)[0]\n",
        "  \n",
        "    return word"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3fwXMJrq2oD"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  input_ids = np.array(sentence[0]).reshape(1,-1)\n",
        "  attention_mask = np.array(sentence[1]).reshape(1,-1)\n",
        "  decoder_data = tokenizer(\"<pad>\")\n",
        "  decoder_data = {'input_ids' : decoder_data['input_ids'][:-1], 'attention_mask' : decoder_data['attention_mask'][:-1]}\n",
        "  decoder_input_ids = np.array(decoder_data['input_ids']).reshape(1,-1)\n",
        "  decoder_attention_mask = np.array(decoder_data['attention_mask']).reshape(1,-1)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model.predict([input_ids, attention_mask, decoder_input_ids, decoder_attention_mask])\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]#.reshape(-1)\n",
        "    predicted_id = np.argmax(predictions, axis=-1)\n",
        "    # probs = temperature(logits=predictions, temperature=1.0)\n",
        "    # predicted_id = nucleus(probs=probs, p=0.90)\n",
        "    predicted_id = predicted_id[0][0]\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == 1:\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder as its input.\n",
        "    decoder_input_ids = np.append(decoder_input_ids.reshape(-1), np.array([predicted_id])).reshape(1,-1)\n",
        "    decoder_attention_mask = np.ones((1, decoder_input_ids.shape[1]))\n",
        "    # print(decoder_input_ids)\n",
        "\n",
        "  return decoder_input_ids\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer.decode([i for i in prediction[0] if i < tokenizer.vocab_size])\n",
        "  return predicted_sentence"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtgzLtwsq2oD"
      },
      "source": [
        "# evaluate()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNmFLqh9q2oD"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "Mvj5TKOGq2oD",
        "outputId": "c8e5526d-5806-487d-c40c-083cfd61d4da"
      },
      "source": [
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=33,\n",
        "    validation_split = 0.1\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1/1 [==============================] - ETA: 0s - loss: 10.2362 - accuracy: 0.0000e+00WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1/1 [==============================] - 52s 52s/step - loss: 10.2362 - accuracy: 0.0000e+00 - val_loss: 10.0637 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 13s 13s/step - loss: 10.1584 - accuracy: 0.0000e+00 - val_loss: 9.9699 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 12s 12s/step - loss: 10.0373 - accuracy: 0.0017 - val_loss: 9.8767 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 13s 13s/step - loss: 9.9645 - accuracy: 0.0164 - val_loss: 9.7839 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 12s 12s/step - loss: 9.8635 - accuracy: 0.0531 - val_loss: 9.6916 - val_accuracy: 0.3770\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 13s 13s/step - loss: 9.7674 - accuracy: 0.1668 - val_loss: 9.6020 - val_accuracy: 0.3852\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 13s 13s/step - loss: 9.6693 - accuracy: 0.3109 - val_loss: 9.5116 - val_accuracy: 0.6967\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 13s 13s/step - loss: 9.5974 - accuracy: 0.4556 - val_loss: 9.4229 - val_accuracy: 0.7049\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 12s 12s/step - loss: 9.4754 - accuracy: 0.5941 - val_loss: 9.3350 - val_accuracy: 0.7049\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 12s 12s/step - loss: 9.3912 - accuracy: 0.6823 - val_loss: 9.2459 - val_accuracy: 0.7049\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 13s 13s/step - loss: 9.2809 - accuracy: 0.7157 - val_loss: 9.1594 - val_accuracy: 0.7049\n",
            "Epoch 12/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-658e5e7df573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h7xV6XXq2oD"
      },
      "source": [
        "# embedding_model.save_weights('/content/drive/MyDrive/univai/Project/T5_emb_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onqy1u6nq2oE"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/univai/Project/T5_univ_man_model.h5')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wdlGScBDvSY",
        "outputId": "9710121b-5ec8-42ae-96b4-be1cf2260fa0"
      },
      "source": [
        "len(x_eval)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "eNjNOb6z1gy9",
        "outputId": "3a40fbe0-9a49-4762-b1fc-a41c2c7d6dc6"
      },
      "source": [
        "predicted_answers = []\n",
        "for i in range(24):\n",
        "  pred_sent = predict([x_eval[0][i], x_eval[1][i]])\n",
        "  predicted_answers.append(pred_sent)\n",
        "  print(pred_sent)\n",
        "df_dict = {'Questions' : val_questions, 'Answers' : predicted_answers}\n",
        "df = pd.DataFrame(df_dict, columns=['Question','Answer'])\n",
        "df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/manual_predicted_T5.csv', index=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-cb467ac85567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredicted_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpred_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mpredicted_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-32c902e0321e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0mpredicted_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-32c902e0321e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# select the last word from the seq_len dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "fWKNOyKuq2oO",
        "outputId": "7991c56e-e461-4012-d985-8cbd728eb931"
      },
      "source": [
        "df = pd.DataFrame(df_dict)\n",
        "df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/manual_predicted_T5.csv', index=False)\n",
        "df"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>answer_me: will the pre-class session be recor...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_me: what is the deadline for quiz submi...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_me: what is the deadline for exercise s...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>answer_me: how many hours do i need to complet...</td>\n",
              "      <td>&lt;pad&gt; yes theaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_me: who will grade the exercise?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>answer_me: why is the auto-grader failing me?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>answer_me: do i do the exercises individually?</td>\n",
              "      <td>&lt;pad&gt; individually.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>answer_me: is the lab compulsory?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>answer_me: will the sessions be recorded?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>answer_me: can i have access to the recorded v...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>answer_me: where are the recordings?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>answer_me: where can i ask questions regarding...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>answer_me: where to find course material?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>answer_me: do we have homework?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>answer_me: where can i find the homework?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>answer_me: where to submit the homework?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>answer_me: where do i find the homework?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>answer_me: where do i submit my homework assig...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>answer_me: will the professor take office hours?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>answer_me: what is the oh zoom link?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>answer_me: what will we do in projects?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>answer_me: what should be the duration of the ...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>answer_me: do i need to submit the project in ...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>answer_me: does attendance count to grading?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Questions                                            Answers\n",
              "0   answer_me: will the pre-class session be recor...                                         <pad> yes.\n",
              "1   answer_me: what is the deadline for quiz submi...                                         <pad> yes.\n",
              "2   answer_me: what is the deadline for exercise s...                                         <pad> yes.\n",
              "3   answer_me: how many hours do i need to complet...  <pad> yes theaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...\n",
              "4             answer_me: who will grade the exercise?                                         <pad> yes.\n",
              "5       answer_me: why is the auto-grader failing me?                                         <pad> yes.\n",
              "6      answer_me: do i do the exercises individually?                                <pad> individually.\n",
              "7                   answer_me: is the lab compulsory?                                         <pad> yes.\n",
              "8           answer_me: will the sessions be recorded?                                         <pad> yes.\n",
              "9   answer_me: can i have access to the recorded v...                                         <pad> yes.\n",
              "10               answer_me: where are the recordings?                                         <pad> yes.\n",
              "11  answer_me: where can i ask questions regarding...                                         <pad> yes.\n",
              "12          answer_me: where to find course material?                                         <pad> yes.\n",
              "13                    answer_me: do we have homework?                                         <pad> yes.\n",
              "14          answer_me: where can i find the homework?                                         <pad> yes.\n",
              "15           answer_me: where to submit the homework?                                         <pad> yes.\n",
              "16           answer_me: where do i find the homework?                                         <pad> yes.\n",
              "17  answer_me: where do i submit my homework assig...                                         <pad> yes.\n",
              "18   answer_me: will the professor take office hours?                                         <pad> yes.\n",
              "19               answer_me: what is the oh zoom link?                                         <pad> yes.\n",
              "20            answer_me: what will we do in projects?                                         <pad> yes.\n",
              "21  answer_me: what should be the duration of the ...                                         <pad> yes.\n",
              "22  answer_me: do i need to submit the project in ...                                         <pad> yes.\n",
              "23       answer_me: does attendance count to grading?                                         <pad> yes."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    }
  ]
}